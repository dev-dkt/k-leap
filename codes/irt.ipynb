{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **코드 설명**\n",
    "\n",
    "- **문항 매개변수 저장**\n",
    "  - `item_parameters` 데이터프레임을 생성하여 문항 번호, 변별도(α), 난이도(β)를 저장합니다.\n",
    "  - `to_csv` 함수를 사용하여 `문항_매개변수.csv` 파일로 저장합니다.\n",
    "  - `encoding='utf-8-sig'` 옵션을 사용하여 한글이 깨지지 않도록 합니다.\n",
    "\n",
    "- **수험생 능력 추정치 저장**\n",
    "  - 개인정보 보호를 위해 필요한 정보만 포함합니다. 여기서는 `이름`과 `능력 추정치`만 저장합니다.\n",
    "  - 만약 수험생을 식별할 수 있는 민감한 정보(예: 주민등록번호 등)가 있다면 제외하거나 익명화해야 합니다.\n",
    "  - `examinee_parameters` 데이터프레임을 생성하여 저장합니다.\n",
    "  - `to_csv` 함수를 사용하여 `수험생_능력_추정치.csv` 파일로 저장합니다.\n",
    "\n",
    "### **추가 사항**\n",
    "\n",
    "- **개인정보 보호**\n",
    "  - 데이터를 저장하거나 공유할 때는 개인정보 보호법 및 관련 규정을 준수해야 합니다.\n",
    "  - 민감한 개인 식별 정보를 저장하거나 공유할 때는 반드시 적절한 동의를 받아야 하며, 필요에 따라 익명화 또는 비식별화 처리를 해야 합니다.\n",
    "\n",
    "- **저장된 결과 활용**\n",
    "  - 저장된 CSV 파일을 불러와서 분석하거나 보고서를 작성할 때 활용할 수 있습니다.\n",
    "  - 예를 들어, Excel에서 파일을 열어 결과를 확인하거나, 다른 분석 프로그램에서 데이터를 불러올 수 있습니다.\n",
    "\n",
    "### **CSV 파일 예시**\n",
    "\n",
    "**문항_매개변수.csv**\n",
    "\n",
    "| 문항 번호 | 변별도 (alpha) | 난이도 (beta) |\n",
    "|-----------|----------------|---------------|\n",
    "| 1         | 1.2345         | -0.5678       |\n",
    "| 2         | 0.9876         | 0.1234        |\n",
    "| ...       | ...            | ...           |\n",
    "\n",
    "**수험생_능력_추정치.csv**\n",
    "\n",
    "| 이름     | 능력 추정치 (theta) |\n",
    "|----------|---------------------|\n",
    "| 홍길동   | 0.4567              |\n",
    "| 이영희   | -0.1234             |\n",
    "| ...      | ...                 |\n",
    "\n",
    "### **참고사항**\n",
    "\n",
    "- **파일 경로 설정**\n",
    "  - `to_csv` 함수에서 파일 경로를 지정하지 않으면 현재 작업 디렉토리에 파일이 저장됩니다.\n",
    "  - 특정 폴더에 저장하고 싶다면 경로를 지정해 주세요. 예: `to_csv('results/문항_매개변수.csv', ...)`\n",
    "\n",
    "- **다른 형식으로 저장**\n",
    "  - 필요에 따라 Excel 파일(`.xlsx`)로 저장하거나, 데이터베이스에 저장할 수도 있습니다.\n",
    "  - Excel로 저장하려면 `pandas`의 `to_excel` 함수를 사용할 수 있습니다.\n",
    "\n",
    "    ```python\n",
    "    item_parameters.to_excel('문항_매개변수.xlsx', index=False)\n",
    "    examinee_parameters.to_excel('수험생_능력_추정치.xlsx', index=False)\n",
    "    ```\n",
    "\n",
    "- **추가 분석**\n",
    "  - 저장된 결과를 활용하여 문항 분석, 수험생 능력 분포 분석 등 추가적인 분석을 수행할 수 있습니다.\n",
    "\n",
    "### **요약**\n",
    "\n",
    "- 추정된 문항 매개변수와 수험생의 능력 추정치를 CSV 파일로 저장하였습니다.\n",
    "- 개인정보 보호를 위해 민감한 정보는 제외하고, 필요한 정보만 포함하였습니다.\n",
    "- 저장된 결과는 추후 분석이나 보고서 작성 등에 활용할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data min: 0\n",
      "Original data max: 5\n",
      "Data adjusted min: 0\n",
      "Data adjusted max: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [theta, alpha, delta_unordered]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 00:13&lt;00:00 Sampling 2 chains, 134 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 14 seconds.\n",
      "There were 134 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Item Discrimination Parameters (alpha):\n",
      "[1.10662241 1.03991959 0.90248713 1.50464158 1.57710065]\n",
      "\n",
      "Estimated Item Difficulty:\n",
      "[ 0.18457249 -0.16157701 -0.21751602 -0.01789174 -0.04638034]\n",
      "\n",
      "Estimated Item Threshold Parameters (delta):\n",
      "[[-1.22959284 -0.37590998 -0.02752064  0.89239833  1.66348758]\n",
      " [-1.93437109 -1.01709614 -0.14739543  0.56644851  1.72452911]\n",
      " [-1.84411857 -0.90513699 -0.00825605  0.61535251  1.05457902]\n",
      " [-1.71895085 -0.44742753  0.35992405  0.67493909  1.04205656]\n",
      " [-2.13032404 -0.76731809 -0.03465823  0.76318294  1.93721569]]\n",
      "\n",
      "Estimated Person Ability Parameters (theta):\n",
      "[ 0.07834941 -0.65297359  0.63308659  1.02547438 -1.21278029  0.49448409\n",
      " -0.07542367 -0.72922874 -0.55692155  0.57996525  0.45653605 -0.19932182\n",
      "  0.46457709 -0.52707634 -0.27568798  0.88097218  0.41795749 -0.05184849\n",
      " -0.69955802 -0.95488248  0.2824283   0.48767391  0.81530902  0.54620747\n",
      " -0.39092528  0.80314099  0.63709897 -0.91936672  0.08685245  0.43486636]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import os\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('응답_데이터_구술.csv', encoding='utf-8')\n",
    "\n",
    "# '득점리스트' 문자열을 정수 리스트로 변환\n",
    "df['responses'] = df['득점리스트'].apply(lambda x: list(map(int, x.split(','))))\n",
    "\n",
    "# 응답 데이터를 DataFrame으로 생성\n",
    "response_data = pd.DataFrame(df['responses'].tolist())\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "data = response_data.values\n",
    "\n",
    "# 피험자 수와 문항 수\n",
    "n_examinees, n_items = data.shape\n",
    "\n",
    "# 원본 데이터의 최소값과 최대값 확인\n",
    "print(\"Original data min:\", data.min())\n",
    "print(\"Original data max:\", data.max())\n",
    "\n",
    "# 응답 데이터를 0부터 시작하는 범주 인덱스로 조정\n",
    "data_adjusted = data.astype(int) - data.min()\n",
    "\n",
    "# 데이터 범위 확인\n",
    "print(\"Data adjusted min:\", data_adjusted.min())\n",
    "print(\"Data adjusted max:\", data_adjusted.max())\n",
    "\n",
    "# 응답 범주 수 계산\n",
    "num_categories = int(data_adjusted.max()) + 1  # 0부터 시작하므로 +1\n",
    "\n",
    "# 각 문항당 임계값 수\n",
    "num_thresholds = num_categories - 1\n",
    "\n",
    "# PyMC를 사용하여 GRM 모델 구축\n",
    "with pm.Model() as grm_model:\n",
    "    # 각 피험자의 능력 모수(theta)\n",
    "    theta = pm.Normal('theta', mu=0, sigma=1, shape=n_examinees)\n",
    "    \n",
    "    # 각 문항의 변별도 모수(alpha)\n",
    "    alpha = pm.HalfNormal('alpha', sigma=1, shape=n_items)\n",
    "    \n",
    "    # 각 문항의 임계값 모수(delta), 정렬되지 않은 상태\n",
    "    delta_unordered = pm.Normal('delta_unordered', mu=0, sigma=1, shape=(n_items, num_thresholds))\n",
    "    \n",
    "    # 각 문항의 임계값을 오름차순으로 정렬\n",
    "    delta_ordered = pm.Deterministic('delta_ordered', pt.sort(delta_unordered, axis=1))\n",
    "    \n",
    "    # 각 범주에 대한 누적 확률 계산\n",
    "    eta = alpha[None, :, None] * (theta[:, None, None] - delta_ordered[None, :, :])\n",
    "    p_cumulative = pm.math.sigmoid(eta)\n",
    "    \n",
    "    # 각 범주의 확률 계산\n",
    "    prob = pm.math.concatenate(\n",
    "        [\n",
    "            pm.math.ones((n_examinees, n_items, 1)),\n",
    "            p_cumulative,\n",
    "            pm.math.zeros((n_examinees, n_items, 1)),\n",
    "        ],\n",
    "        axis=2,\n",
    "    )\n",
    "    prob = prob[:, :, :-1] - prob[:, :, 1:]\n",
    "    \n",
    "    # 확률을 정규화하여 합이 1이 되도록 함\n",
    "    prob = prob / prob.sum(axis=2, keepdims=True)\n",
    "    \n",
    "    # 확률 값이 유효한 범위 내에 있도록 클리핑\n",
    "    prob = pm.math.clip(prob, 1e-10, 1.0 - 1e-10)\n",
    "    \n",
    "    # 관측된 데이터 정의\n",
    "    observed = pm.Categorical('observed', p=prob, observed=data_adjusted)\n",
    "    \n",
    "    # 모델 샘플링\n",
    "    trace = pm.sample(\n",
    "        1000,\n",
    "        tune=1000,\n",
    "        cores=2,\n",
    "        random_seed=42,\n",
    "        return_inferencedata=True,\n",
    "    )\n",
    "\n",
    "# 추정된 문항 모수 추출\n",
    "alpha_est = trace.posterior['alpha'].mean(dim=['chain', 'draw']).values\n",
    "delta_est = trace.posterior['delta_ordered'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# 문항 난이도 계산 (임계값들의 평균)\n",
    "item_difficulty = delta_est.mean(axis=1)\n",
    "\n",
    "# 추정된 피험자 능력 모수 추출\n",
    "theta_est = trace.posterior['theta'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# 문항 모수 저장\n",
    "item_parameters = pd.DataFrame({\n",
    "    '문항 번호': np.arange(1, n_items + 1),\n",
    "    '변별도 (alpha)': alpha_est,\n",
    "    '난이도': item_difficulty\n",
    "})\n",
    "\n",
    "# 임계값을 DataFrame에 추가\n",
    "for k in range(num_thresholds):\n",
    "    item_parameters[f'임계값_{k + 1}'] = delta_est[:, k]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "item_parameters.to_csv('문항_매개변수_구술.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 피험자 능력 추정치 저장\n",
    "examinee_parameters = df[['이름', '외국인 등록번호']].copy()\n",
    "examinee_parameters['능력 추정치 (theta)'] = theta_est\n",
    "\n",
    "# CSV 파일로 저장\n",
    "examinee_parameters.to_csv('수험생_능력_추정치_구술.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 샘플링 결과 저장\n",
    "trace.to_netcdf('irt_trace_구술.nc')\n",
    "\n",
    "# 결과 출력\n",
    "print('Estimated Item Discrimination Parameters (alpha):')\n",
    "print(alpha_est)\n",
    "\n",
    "print('\\nEstimated Item Difficulty:')\n",
    "print(item_difficulty)\n",
    "\n",
    "print('\\nEstimated Item Threshold Parameters (delta):')\n",
    "print(delta_est)\n",
    "\n",
    "print('\\nEstimated Person Ability Parameters (theta):')\n",
    "print(theta_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "from pymc.distributions.transforms import Ordered\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('응답_데이터_구술.csv', encoding='utf-8')\n",
    "\n",
    "# Convert '득점리스트' strings to lists of integers\n",
    "df['responses'] = df['득점리스트'].apply(lambda x: list(map(int, x.split(','))))\n",
    "\n",
    "# Create a DataFrame of responses\n",
    "response_data = pd.DataFrame(df['responses'].tolist())\n",
    "\n",
    "# Convert response_data to a NumPy array\n",
    "data = response_data.values\n",
    "\n",
    "# Number of examinees and items\n",
    "n_examinees, n_items = data.shape\n",
    "\n",
    "# Original data min and max\n",
    "print(\"Original data min:\", data.min())\n",
    "print(\"Original data max:\", data.max())\n",
    "\n",
    "# Adjust observed data to be category indices starting from 0\n",
    "data_adjusted = data.astype(int) - data.min()  # Adjust categories to start from 0\n",
    "\n",
    "# Verify data ranges\n",
    "print(\"Data adjusted min:\", data_adjusted.min())\n",
    "print(\"Data adjusted max:\", data_adjusted.max())\n",
    "\n",
    "# Number of categories\n",
    "num_categories = int(data_adjusted.max()) + 1  # Categories start from 0\n",
    "\n",
    "# Number of thresholds per item\n",
    "num_thresholds = num_categories - 1\n",
    "\n",
    "# Build the GRM model using PyMC\n",
    "with pm.Model() as grm_model:\n",
    "    # Ability parameters for each examinee\n",
    "    theta = pm.Normal('theta', mu=0, sigma=1, shape=n_examinees)\n",
    "    \n",
    "    # Discrimination parameters for each item\n",
    "    alpha = pm.HalfNormal('alpha', sigma=1, shape=n_items)\n",
    "    \n",
    "    # Threshold parameters for each item (unconstrained)\n",
    "    delta_unordered = pm.Normal('delta_unordered', mu=0, sigma=1, shape=(n_items, num_thresholds))\n",
    "    \n",
    "    # Ensure that thresholds are ordered for each item\n",
    "    delta_ordered = pm.Deterministic('delta_ordered', pt.sort(delta_unordered, axis=1))\n",
    "    \n",
    "    # Compute the cumulative probabilities for each category\n",
    "    # For each item, compute P(Y ≥ k)\n",
    "    eta = alpha[None, :, None] * (theta[:, None, None] - delta_ordered[None, :, :])\n",
    "    p_cumulative = pm.math.sigmoid(eta)\n",
    "    \n",
    "    # Compute the probability of each category\n",
    "    prob = pm.math.concatenate(\n",
    "        [\n",
    "            pm.math.ones((n_examinees, n_items, 1)),\n",
    "            p_cumulative,\n",
    "            pm.math.zeros((n_examinees, n_items, 1)),\n",
    "        ],\n",
    "        axis=2,\n",
    "    )\n",
    "    prob = prob[:, :, :-1] - prob[:, :, 1:]\n",
    "    \n",
    "    # Normalize probabilities to ensure they sum to 1\n",
    "    prob = prob / prob.sum(axis=2, keepdims=True)\n",
    "    \n",
    "    # Ensure probabilities are within valid range\n",
    "    prob = pm.math.clip(prob, 1e-10, 1.0 - 1e-10)\n",
    "    \n",
    "    # Observed data\n",
    "    observed = pm.Categorical('observed', p=prob, observed=data_adjusted)\n",
    "    \n",
    "    # Sample from the posterior distribution\n",
    "    trace = pm.sample(\n",
    "        1000,\n",
    "        tune=1000,\n",
    "        cores=2,\n",
    "        random_seed=42,\n",
    "        return_inferencedata=True,\n",
    "    )\n",
    "\n",
    "# Extract estimated item parameters\n",
    "alpha_est = trace.posterior['alpha'].mean(dim=['chain', 'draw']).values\n",
    "delta_est = trace.posterior['delta_ordered'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Extract estimated person abilities\n",
    "theta_est = trace.posterior['theta'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Save item parameters\n",
    "item_parameters = pd.DataFrame({\n",
    "    '문항 번호': np.arange(1, n_items+1),\n",
    "    '변별도 (alpha)': alpha_est\n",
    "})\n",
    "\n",
    "# Add thresholds to the DataFrame\n",
    "for k in range(num_thresholds):\n",
    "    item_parameters[f'임계값_{k+1}'] = delta_est[:, k]\n",
    "\n",
    "# Save to CSV\n",
    "item_parameters.to_csv('문항_매개변수_구술.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Save examinee abilities\n",
    "examinee_parameters = df[['이름', '외국인 등록번호']].copy()\n",
    "examinee_parameters['능력 추정치 (theta)'] = theta_est\n",
    "\n",
    "# Save to CSV\n",
    "examinee_parameters.to_csv('수험생_능력_추정치_구술.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Save the trace\n",
    "trace.to_netcdf('irt_trace_구술.nc')\n",
    "\n",
    "# Output the results\n",
    "print('Estimated Item Discrimination Parameters (alpha):')\n",
    "print(alpha_est)\n",
    "\n",
    "print('\\nEstimated Item Threshold Parameters (delta):')\n",
    "print(delta_est)\n",
    "\n",
    "print('\\nEstimated Person Ability Parameters (theta):')\n",
    "print(theta_est)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
